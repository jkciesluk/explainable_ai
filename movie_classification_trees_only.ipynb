{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azevedo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, log_loss\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Set random seed\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cleaned data from csv\n",
    "df = pd.read_csv('input/movie_data_tmbd_cleaned.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17425 entries, 0 to 17424\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   adult                 17425 non-null  int64  \n",
      " 1   budget                17425 non-null  int64  \n",
      " 2   genres                17410 non-null  object \n",
      " 3   original_language     17425 non-null  object \n",
      " 4   overview              17425 non-null  object \n",
      " 5   popularity            17425 non-null  float64\n",
      " 6   production_companies  16811 non-null  object \n",
      " 7   production_countries  17253 non-null  object \n",
      " 8   revenue               17425 non-null  int64  \n",
      " 9   runtime               17425 non-null  float64\n",
      " 10  spoken_languages      17376 non-null  object \n",
      " 11  status                17425 non-null  object \n",
      " 12  tagline               17425 non-null  object \n",
      " 13  video                 17425 non-null  int64  \n",
      " 14  vote_average          17425 non-null  float64\n",
      " 15  vote_count            17425 non-null  float64\n",
      " 16  cast                  17404 non-null  object \n",
      " 17  directors             17415 non-null  object \n",
      " 18  release_year          17425 non-null  int64  \n",
      " 19  release_month         17425 non-null  int64  \n",
      " 20  release_day           17425 non-null  int64  \n",
      " 21  category              17425 non-null  object \n",
      "dtypes: float64(4), int64(7), object(11)\n",
      "memory usage: 2.9+ MB\n",
      "None\n",
      "   adult  budget         genres original_language  \\\n",
      "0      0       0  Drama,Western                en   \n",
      "1      0       0    Documentary                fr   \n",
      "2      0       0        History                it   \n",
      "3      0       0          Drama                en   \n",
      "4      0       0        Western                en   \n",
      "\n",
      "                                            overview  popularity  \\\n",
      "0  A fiercely independent cowboy arranges to have...       8.262   \n",
      "1  Documents the lives of infamous fakers Elmyr d...       7.830   \n",
      "2  While on holiday in Rhodes, Athenian war hero ...       9.668   \n",
      "3  In early 1960s London, barrister Melville Farr...       5.896   \n",
      "4  Respected black cavalry Sergeant Brax Rutledge...       6.003   \n",
      "\n",
      "                                production_companies  \\\n",
      "0                                   Joel Productions   \n",
      "1                                   SACI,Janus Films   \n",
      "2  Produzioni Atlas Consorziate,Procusa,Comptoir ...   \n",
      "3                                                NaN   \n",
      "4        John Ford Productions,Warner Bros. Pictures   \n",
      "\n",
      "       production_countries  revenue  runtime  ...  \\\n",
      "0  United States of America        0    107.0  ...   \n",
      "1       Germany,France,Iran        0     89.0  ...   \n",
      "2        Spain,France,Italy        0    127.0  ...   \n",
      "3            United Kingdom        0     90.0  ...   \n",
      "4  United States of America        0    111.0  ...   \n",
      "\n",
      "                                             tagline video vote_average  \\\n",
      "0               Life can never cage a man like this!     0          7.5   \n",
      "1                                            Unknown     0          7.5   \n",
      "2  A monster statue of bronze and stone...A fabul...     0          6.0   \n",
      "3  A Daring Picture About the World's Most Un-tal...     0          7.5   \n",
      "4  Forget all the suspense you have ever seen! Fo...     0          7.0   \n",
      "\n",
      "   vote_count                                               cast  \\\n",
      "0        70.0  Kirk Douglas,Gena Rowlands,Walter Matthau,Carr...   \n",
      "1       178.0  Orson Welles,Elmyr de Hory,Clifford Irving,Oja...   \n",
      "2        94.0  Rory Calhoun,Lea Massari,Georges Marchal,Conra...   \n",
      "3        57.0  Dirk Bogarde,Sylvia Syms,Dennis Price,Anthony ...   \n",
      "4        59.0  Jeffrey Hunter,Woody Strode,Constance Towers,B...   \n",
      "\n",
      "       directors release_year release_month  release_day  category  \n",
      "0   David Miller         1962             5           24     great  \n",
      "1   Orson Welles         1975             3           12     great  \n",
      "2   Sergio Leone         1961             6           15  mediocre  \n",
      "3  Basil Dearden         1961             8            1     great  \n",
      "4      John Ford         1960             5           18      good  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print info about the data\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['vote_average', 'category'])\n",
    "# Drop text columns\n",
    "# X = X.drop(columns=['belongs_to_collection', 'tagline', 'overview'])\n",
    "Y = df['category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  13940\n",
      "Test set size:  3485\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Encode target variable (Y) using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train_encoded = label_encoder.fit_transform(Y_train)\n",
    "Y_test_encoded = label_encoder.transform(Y_test)\n",
    "\n",
    "\n",
    "print(\"Training set size: \", len(X_train))\n",
    "print(\"Test set size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17425 entries, 0 to 17424\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   adult                 17425 non-null  int64  \n",
      " 1   budget                17425 non-null  int64  \n",
      " 2   genres                17410 non-null  object \n",
      " 3   original_language     17425 non-null  object \n",
      " 4   overview              17425 non-null  object \n",
      " 5   popularity            17425 non-null  float64\n",
      " 6   production_companies  16811 non-null  object \n",
      " 7   production_countries  17253 non-null  object \n",
      " 8   revenue               17425 non-null  int64  \n",
      " 9   runtime               17425 non-null  float64\n",
      " 10  spoken_languages      17376 non-null  object \n",
      " 11  status                17425 non-null  object \n",
      " 12  tagline               17425 non-null  object \n",
      " 13  video                 17425 non-null  int64  \n",
      " 14  vote_count            17425 non-null  float64\n",
      " 15  cast                  17404 non-null  object \n",
      " 16  directors             17415 non-null  object \n",
      " 17  release_year          17425 non-null  int64  \n",
      " 18  release_month         17425 non-null  int64  \n",
      " 19  release_day           17425 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(10)\n",
      "memory usage: 2.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   adult  budget         genres original_language  \\\n",
      "0      0       0  Drama,Western                en   \n",
      "1      0       0    Documentary                fr   \n",
      "2      0       0        History                it   \n",
      "3      0       0          Drama                en   \n",
      "4      0       0        Western                en   \n",
      "\n",
      "                                            overview  popularity  \\\n",
      "0  A fiercely independent cowboy arranges to have...       8.262   \n",
      "1  Documents the lives of infamous fakers Elmyr d...       7.830   \n",
      "2  While on holiday in Rhodes, Athenian war hero ...       9.668   \n",
      "3  In early 1960s London, barrister Melville Farr...       5.896   \n",
      "4  Respected black cavalry Sergeant Brax Rutledge...       6.003   \n",
      "\n",
      "                                production_companies  \\\n",
      "0                                   Joel Productions   \n",
      "1                                   SACI,Janus Films   \n",
      "2  Produzioni Atlas Consorziate,Procusa,Comptoir ...   \n",
      "3                                                NaN   \n",
      "4        John Ford Productions,Warner Bros. Pictures   \n",
      "\n",
      "       production_countries  revenue  runtime          spoken_languages  \\\n",
      "0  United States of America        0    107.0           Español,English   \n",
      "1       Germany,France,Iran        0     89.0  English,Français,Español   \n",
      "2        Spain,France,Italy        0    127.0                  Italiano   \n",
      "3            United Kingdom        0     90.0                   English   \n",
      "4  United States of America        0    111.0                   English   \n",
      "\n",
      "     status                                            tagline  video  \\\n",
      "0  Released               Life can never cage a man like this!      0   \n",
      "1  Released                                            Unknown      0   \n",
      "2  Released  A monster statue of bronze and stone...A fabul...      0   \n",
      "3  Released  A Daring Picture About the World's Most Un-tal...      0   \n",
      "4  Released  Forget all the suspense you have ever seen! Fo...      0   \n",
      "\n",
      "   vote_count                                               cast  \\\n",
      "0        70.0  Kirk Douglas,Gena Rowlands,Walter Matthau,Carr...   \n",
      "1       178.0  Orson Welles,Elmyr de Hory,Clifford Irving,Oja...   \n",
      "2        94.0  Rory Calhoun,Lea Massari,Georges Marchal,Conra...   \n",
      "3        57.0  Dirk Bogarde,Sylvia Syms,Dennis Price,Anthony ...   \n",
      "4        59.0  Jeffrey Hunter,Woody Strode,Constance Towers,B...   \n",
      "\n",
      "       directors  release_year  release_month  release_day  \n",
      "0   David Miller          1962              5           24  \n",
      "1   Orson Welles          1975              3           12  \n",
      "2   Sergio Leone          1961              6           15  \n",
      "3  Basil Dearden          1961              8            1  \n",
      "4      John Ford          1960              5           18  \n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical, categorical, boolean, and text features\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "\n",
    "\n",
    "numerical_features = ['budget', 'revenue', 'popularity', 'runtime', 'vote_count', 'release_year', 'release_month', 'release_day']\n",
    "categorical_features = ['original_language', 'status']\n",
    "boolean_features = ['adult', 'video']\n",
    "text_features = ['overview', 'tagline']\n",
    "list_based_features = ['genres', 'production_companies', 'production_countries', 'cast', 'directors']\n",
    "\n",
    "# 1. Numerical transformer: Impute missing values and standardize\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 2. Categorical transformer: Impute missing values and one-hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3. Boolean transformer: Ensure 0/1 values\n",
    "boolean_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# 4. Text transformer: Use TF-IDF for text columns\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=100))  # Adjust max_features as needed\n",
    "])\n",
    "\n",
    "# 5. List-based transformer: Convert list of items into count vectors (like multi-hot encoding)\n",
    "def list_to_str(column):\n",
    "    return column.apply(lambda x: ','.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "list_transformer = Pipeline(steps=[\n",
    "    ('to_string', FunctionTransformer(list_to_str, validate=False)),\n",
    "    ('countvec', CountVectorizer(tokenizer=lambda x: x.split(','), max_features=100))  # Adjust max_features as needed\n",
    "])\n",
    "\n",
    "# Combine all transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('bool', boolean_transformer, boolean_features),\n",
    "        ('overview', text_transformer, 'overview'),\n",
    "        ('tagline', text_transformer, 'tagline'),\n",
    "        ('genres', list_transformer, 'genres'),\n",
    "        ('production_companies', list_transformer, 'production_companies'),\n",
    "        ('production_countries', list_transformer, 'production_countries'),\n",
    "        ('cast', list_transformer, 'cast'),\n",
    "        ('directors', list_transformer, 'directors')\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transparent Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions needed to help calculate the Information Gain Ratio to be used with the tree. Attention for being a Multi-class Classification problem (4 possible values).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    #Portion of 'bad' = counts['bad']/np.sum(counts)\n",
    "    entropy_value = np.sum([(-counts[i]/np.sum(counts)) * np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8363119037104076\n",
      "['bad' 'good' 'great' 'mediocre']\n",
      "[1794 7064 3160 5407]\n"
     ]
    }
   ],
   "source": [
    "# 'category' has 4 possible values, so Entropy can range from 0 (perfectly pure, all values in one class) to 2 (all classes represented equally in the same number each)\n",
    "e = entropy(df['category'])\n",
    "elements, counts = np.unique(df['category'], return_counts=True)\n",
    "print(e)\n",
    "print(elements)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Gain -> the expected reduction in entropy (more proximate to 0 = more pure = reached decision) caused by partitioning the dataset according to split_attribute_name\n",
    "#                 -> the amount of information gained by spliting the data using split_attribute_name\n",
    "#                 -> higher values are better\n",
    "def info_gain(data, split_attribute_name, target_name='category'):\n",
    "    total_entropy = entropy(data[target_name]) #entropy(df['category'])\n",
    "    \n",
    "    # All possible values for the splitting attribute\n",
    "    values, counts = np.unique(data[split_attribute_name].astype(str), return_counts=True)\n",
    "    \n",
    "    weighted_entropy = np.sum([(counts[i]/np.sum(counts)) * entropy(data.where(data[split_attribute_name] == values[i]).dropna()[target_name]) for i in range(len(values))])\n",
    "    \n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13807680725863491\n",
      "1.3861229637877837\n"
     ]
    }
   ],
   "source": [
    "igainex1 = info_gain(df, 'budget')\n",
    "print(igainex1)\n",
    "\n",
    "igainex2 = info_gain(df, 'popularity')\n",
    "print(igainex2)\n",
    "\n",
    "igainex3 = info_gain(df, 'spoken_languages')\n",
    "print(igainex3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Gain Ratio  ->  ratio of information gain to the intrinsic information\n",
    "#                        -> reduce a bias towards multi-valued attributes by taking the number and size of branches into account when choosing an attribute, biases the decision tree against considering attributes with a large number of distinct values (ex: ID would lead to maximum purity)\n",
    "#                        -> higher values are better\n",
    "def info_gain_ratio(data, split_attribute_name, target_name='category'):\n",
    "    information_gain = info_gain(data, split_attribute_name, target_name)\n",
    "    \n",
    "    # Split information = Intrinsic value  -> is a positive number that describes the potential worth of splitting a branch from a node. \n",
    "    # This in turn is the intrinsic value that the spliting attribute possesses and will be used to remove the bias in the information gain ratio calculation. (src: Wikipedia)\n",
    "    values, counts = np.unique(data[split_attribute_name], return_counts=True)\n",
    "    split_information = np.sum([(-counts[i]/np.sum(counts)) * np.log2(counts[i]/np.sum(counts)) for i in range(len(values))])\n",
    "    \n",
    "    # Avoidinge division by zero\n",
    "    if split_information == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Gain ratio is the information gain divided by intrinsic value\n",
    "    return information_gain / split_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['adult', 'budget', 'genres', 'original_language', 'overview',\n",
      "       'popularity', 'production_companies', 'production_countries', 'revenue',\n",
      "       'runtime', 'spoken_languages', 'status', 'tagline', 'video',\n",
      "       'vote_average', 'vote_count', 'cast', 'directors', 'release_year',\n",
      "       'release_month', 'release_day', 'category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031687744047573504\n",
      "0.10391494099843424\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m igrex2 \u001b[38;5;241m=\u001b[39m info_gain_ratio(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopularity\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(igrex2)\n\u001b[1;32m----> 7\u001b[0m igrex3 \u001b[38;5;241m=\u001b[39m \u001b[43minfo_gain_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspoken_languages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(igrex3)\n",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m, in \u001b[0;36minfo_gain_ratio\u001b[1;34m(data, split_attribute_name, target_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo_gain_ratio\u001b[39m(data, split_attribute_name, target_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     information_gain \u001b[38;5;241m=\u001b[39m \u001b[43minfo_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_attribute_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Split information = Intrinsic value  -> is a positive number that describes the potential worth of splitting a branch from a node. \u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# This in turn is the intrinsic value that the spliting attribute possesses and will be used to remove the bias in the information gain ratio calculation. (src: Wikipedia)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     values, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(data[split_attribute_name], return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36minfo_gain\u001b[1;34m(data, split_attribute_name, target_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m total_entropy \u001b[38;5;241m=\u001b[39m entropy(data[target_name]) \u001b[38;5;66;03m#entropy(df['category'])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# All possible values for the splitting attribute\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m values, counts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit_attribute_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m weighted_entropy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum([(counts[i]\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(counts)) \u001b[38;5;241m*\u001b[39m entropy(data\u001b[38;5;241m.\u001b[39mwhere(data[split_attribute_name] \u001b[38;5;241m==\u001b[39m values[i])\u001b[38;5;241m.\u001b[39mdropna()[target_name]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(values))])\n\u001b[0;32m     12\u001b[0m information_gain \u001b[38;5;241m=\u001b[39m total_entropy \u001b[38;5;241m-\u001b[39m weighted_entropy\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "igrex1 = info_gain_ratio(df, 'budget')\n",
    "print(igrex1)\n",
    "\n",
    "igrex2 = info_gain_ratio(df, 'popularity')\n",
    "print(igrex2)\n",
    "\n",
    "igrex3 = info_gain_ratio(df, 'spoken_languages')\n",
    "print(igrex3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.5 Recursive Algorithm to build the Decision Tree\n",
    "def c45_tree(data, original_data, features, target_name='category', parent_node_class=None):\n",
    "    \n",
    "    # Base case 1: If all target values are the same, return that class\n",
    "    if len(np.unique(data[target_name])) <= 1:\n",
    "        return np.unique(data[target_name])[0]\n",
    "    \n",
    "    # Base case 2: If dataset is empty, return the class of the parent node\n",
    "    elif len(data) == 0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    # Base case 3: If no more features to split on, return the majority class of the current node\n",
    "    elif len(features) == 0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    # Base case 4: If the data is pure (contains only one class)\n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_name])[np.argmax(np.unique(data[target_name], return_counts=True)[1])]\n",
    "        \n",
    "        # Select the feature with the highest gain ratio\n",
    "        gain_ratios = [info_gain_ratio(data, feature, target_name) for feature in features]\n",
    "        best_feature_index = np.argmax(gain_ratios)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        # Create the tree structure (dictionary)\n",
    "        tree = {best_feature: {}}\n",
    "        \n",
    "        # Remove the best feature from the feature list\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        # For each value of the best feature, split the data and recursively build the tree\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "        \n",
    "            subtree = c45_tree(sub_data, original_data, features, target_name, parent_node_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "        \n",
    "        return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m featureList \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m----> 2\u001b[0m c45tree \u001b[38;5;241m=\u001b[39m \u001b[43mc45_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatureList\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(c45tree)\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36mc45_tree\u001b[1;34m(data, original_data, features, target_name, parent_node_class)\u001b[0m\n\u001b[0;32m     18\u001b[0m parent_node_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(data[target_name])[np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39munique(data[target_name], return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Select the feature with the highest gain ratio\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m gain_ratios \u001b[38;5;241m=\u001b[39m [info_gain_ratio(data, feature, target_name) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m     22\u001b[0m best_feature_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(gain_ratios)\n\u001b[0;32m     23\u001b[0m best_feature \u001b[38;5;241m=\u001b[39m features[best_feature_index]\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m parent_node_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(data[target_name])[np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39munique(data[target_name], return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Select the feature with the highest gain ratio\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m gain_ratios \u001b[38;5;241m=\u001b[39m [\u001b[43minfo_gain_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m     22\u001b[0m best_feature_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(gain_ratios)\n\u001b[0;32m     23\u001b[0m best_feature \u001b[38;5;241m=\u001b[39m features[best_feature_index]\n",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m, in \u001b[0;36minfo_gain_ratio\u001b[1;34m(data, split_attribute_name, target_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo_gain_ratio\u001b[39m(data, split_attribute_name, target_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     information_gain \u001b[38;5;241m=\u001b[39m \u001b[43minfo_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_attribute_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Split information = Intrinsic value  -> is a positive number that describes the potential worth of splitting a branch from a node. \u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# This in turn is the intrinsic value that the spliting attribute possesses and will be used to remove the bias in the information gain ratio calculation. (src: Wikipedia)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     values, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(data[split_attribute_name], return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36minfo_gain\u001b[1;34m(data, split_attribute_name, target_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m total_entropy \u001b[38;5;241m=\u001b[39m entropy(data[target_name]) \u001b[38;5;66;03m#entropy(df['category'])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# All possible values for the splitting attribute\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m values, counts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit_attribute_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m weighted_entropy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum([(counts[i]\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(counts)) \u001b[38;5;241m*\u001b[39m entropy(data\u001b[38;5;241m.\u001b[39mwhere(data[split_attribute_name] \u001b[38;5;241m==\u001b[39m values[i])\u001b[38;5;241m.\u001b[39mdropna()[target_name]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(values))])\n\u001b[0;32m     12\u001b[0m information_gain \u001b[38;5;241m=\u001b[39m total_entropy \u001b[38;5;241m-\u001b[39m weighted_entropy\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "featureList = df.columns[df.columns != 'category'].tolist()\n",
    "c45tree = c45_tree(df, df, featureList)\n",
    "print(c45tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART Algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
